# Welcome to My Research Portfolio ðŸ‘‹

Hi! I am **Yafu Li**, a researcher at Shanghai AI Lab, currently working under the supervision of [Prof. Yu Cheng](https://ych133.github.io/). I earned my PhD through joint training at Zhejiang University and Westlake University under the guidance of [Prof. Yue Zhang](https://frcchang.github.io/).

My research focuses on **test-time scaling**, **trustworthy AI**, and **machine translation**.

:sparkles: :sparkles: :sparkles:   
We are looking for **interns** and joint **PhD candidates** (with THU, PKU, SJTU, FDU, etc.) to work on cutting-edge research in large language models. Our focus areas include zero reinforcement learning (e.g., R1-zero), test-time scaling, and trustworthy AI. If you are interested, please feel free to contact me at [yafuly@gmail.com](mailto:yafuly@gmail.com).

---

## Reasoning and Inference Scaling ðŸš€
- **Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models**
  [Paper Link](https://arxiv.org/abs/2505.14810) | [Github Project :octocat:](https://github.com/TingchenFu/MathIF/tree/main)

- **Learning to Reason under Off-Policy Guidance**  
  [Paper Link](https://arxiv.org/abs/2504.14945) | [Github Project :octocat:](https://github.com/ElliottYan/LUFFY)

- **A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond**  
  [Paper Link](https://arxiv.org/abs/2503.21614) | [GitHub Project :octocat:](https://github.com/XiaoYee/Awesome_Efficient_LRM_Reasoning)

- **Test-Time Preference Optimization: On-the-Fly Alignment via Iterative Textual Feedback**  
  [Paper Link](https://arxiv.org/abs/2501.12895) | [GitHub Project :octocat:](https://github.com/yafuly/TPO)

- **From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning**  
  [Paper Link](https://arxiv.org/abs/2501.11877) | [GitHub Project :octocat:](https://github.com/Linzwcs/AFT)

- **Multi-LLM Collaborative Search for Complex Problem Solving**  
  [Paper Link](https://arxiv.org/abs/2502.18873)


