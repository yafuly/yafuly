<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yafu Li</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yafu Li (ÊùéÈõÖÂ§´)</name>
              </p>
              <p>
                I am a postdoctoral researcher at The Chinese University of Hong Kong, working under the supervision of <a href="https://ych133.github.io/">Prof. Yu Cheng</a>. I earned my PhD through a joint program between Zhejiang University and Westlake University, advised by <a href="https://frcchang.github.io/">Prof. Yue Zhang</a>.
                <br><br>
                I received my Bachelor's degree from Wuhan University, followed by a Master's degree from the University of Edinburgh, where I was supervised by <a href="https://homepages.inf.ed.ac.uk/alex/">Prof. Alex Lascarides</a>.
                During my PhD, I interned at Tencent AI Lab and collaborated closely with <a href="https://nealcly.github.io/">Dr. Leyang Cui</a> and <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Dr. Wei Bi</a>.
              </p>
              
              </p>
              <p style="text-align:center">
                <a href="mailto:yafuly@gmail.com">Email</a> &nbsp/&nbsp
                <!-- CV(<a href="data/cv_en.pdf">En</a>/<a href="data/cv_zh.pdf">‰∏≠Êñá</a>) &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=gEceD-sAAAAJ">Google Scholar</a> &nbsp/&nbsp
		      <!-- <a href="https://www.semanticscholar.org/author/Yafu-Li/2110450452">Semantic Scholar</a> &nbsp/&nbsp -->
                <a href="https://twitter.com/yafuly">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/yafuly">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/self2.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Open Positions</heading>
            <p>
              We are looking for <strong>full-time researchers</strong>, <strong>research interns</strong> and <strong>joint PhD students</strong> (with THU, PKU, SJTU, FDU, etc.) to work on cutting-edge research in large language models. 
            </p>
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Areas</heading>
              <p>
                My research focuses on reasoning, trustworthy AI and multilinguality. *: equal contributions. &#8224: project lead or corresponding author.
              </p>
            </td>
          </tr>
        </tbody></table>



        
        <!-- Inference Scaling Section -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Reasoning</heading>
            </td>
          </tr>
        </tbody></table>
        
        <!-- Papers under Inference Scaling -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/exgrpo.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2510.02245" id="conf_deepfake-detect">
                <papertitle>ExGRPO: Learning to Reason from Experience</papertitle>
              </a>
              <br>
              Runzhe Zhan, <strong>Yafu Li</strong><sup>&#8224</sup>, Zhi Wang, Xiaoye Qu, Dongrui Liu, Jing Shao, Derek F. Wong, Yu Cheng
              <br>
              <em>preprint</em>
              <br>
              <a href="https://github.com/ElliottYan/LUFFY/tree/main/ExGRPO">Github</a>
              /
              <a href="https://arxiv.org/abs/2510.02245">Paper</a>
              <p></p>
              <p>Boosting reasoning performance with the model's own experience.</p>
            </td>
          </tr>
          


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mathif.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2505.14810" id="conf_deepfake-detect">
                <papertitle>Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models</papertitle>
              </a>
              <br>
              Tingchen Fu, Jiawei Gu, <strong>Yafu Li</strong><sup>&#8224</sup>, Xiaoye Qu, Yu Cheng
              <br>
              <em>preprint</em>
              <br>
              <a href="https://github.com/tingchenfu/mathif">Github</a>
              /
              <a href="https://arxiv.org/abs/2505.14810">Paper</a>
              <p></p>
              <p>A tension between scaling up reasoning capacity and maintaining controllability.</p>
            </td>
          </tr>
          
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/luffy.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2504.14945" id="conf_deepfake-detect">
                <papertitle>Learning to Reason under Off-Policy Guidance</papertitle>
              </a>
              <br>
              Jianhao Yan<sup>*</sup>, <strong>Yafu Li</strong><sup>*</sup><sup>&#8224</sup>, Zican Hu, Zhi Wang, Ganqu Cui, Xiaoye Qu, Yu Cheng, Yue Zhang
              <br>
              <em> <strong>NeurIPS</strong>, 2025</em>
              <br>
              <a href="https://github.com/ElliottYan/LUFFY">Github</a>
              /
              <a href="https://arxiv.org/abs/2504.14945">Paper</a>
              <p></p>
              <p>A RL framework to boost reasoning performance using off-policy guidance.</p>
            </td>
          </tr>
          
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/efficient_lrm_survey.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2503.21614" id="conf_deepfake-detect">
                <papertitle>A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond</papertitle>
              </a>
              <br>
              Xiaoye Qu<sup>*</sup><sup>&#8224</sup>, <strong>Yafu Li</strong><sup>*</sup><sup>&#8224</sup>, Zhaochen Su, Weigao Sun, Jianhao Yan, Dongrui Liu, Ganqu Cui, Daizong Liu, Shuxian Liang, Junxian He, Peng Li, Wei Wei, Jing Shao, Chaochao Lu, Yue Zhang, Xian-Sheng Hua, Bowen Zhou, Yu Cheng
              <br>
              <em>preprint</em>
              <br>
              <a href="https://github.com/XiaoYee/Awesome_Efficient_LRM_Reasoning">Github</a>
              /
              <a href="https://arxiv.org/abs/2503.21614">Paper</a>
              <p></p>
              <p>A survey of efficient reasoning for Large Reasoning Models.</p>
            </td>
          </tr>
          
        
          
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tpo.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2501.12895" id="conf_deepfake-detect">
                <papertitle>Test-Time Preference Optimization: On-the-Fly Alignment via Iterative Textual Feedback</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong>,
              Xuyang Hu,
              Xiaoye Qu,
              Linjie Li,
              Yu Cheng
              <br>
              <em><strong>ICML</strong>, 2025</em>
              <br>
              <a href="https://github.com/yafuly/TPO">Github</a>
              /
              <a href="https://arxiv.org/abs/2501.12895">Paper</a>
              <p></p>
              <p>Test-Time Preference Optimization (TPO) that aligns LLMs during inference via textual feedbacks.</p>
            </td>
          </tr>
        
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/aft.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2501.11877" id="conf_deepfake-detect">
                <papertitle>From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong><sup>*</sup>,
              Zhilin Wang<sup>*</sup>,
              Tingchen Fu,
              Ganqu Cui,
              Sen Yang,
              Yu Cheng
              <br>
              <em>preprint</em>
              <br>
              <a href="https://github.com/Linzwcs/AFT">Github</a>
              /
              <a href="https://arxiv.org/abs/2501.11877">Paper</a>
              <p></p>
              <p>We present Aggregation Fine-Tuning (AFT) where the model learns to aggregate multiple drafts into a single answer.</p>
            </td>
          </tr> -->
          

    

        <!-- Trustworthy AI Section -->
<!-- Papers under Inference Scaling -->
        


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Trustworthy AI</heading>
            </td>
          </tr>
        </tbody></table>
        
        <!-- Papers under Trustworthy AI -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/specbench.jpg" alt="SpecBench" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2509.14760" id="conf_specbench">
                <papertitle>Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Deliberation</papertitle>
              </a>
              <br>
              Haoran Zhang, <strong>Yafu Li</strong><sup>&#8224</sup>, Xuyang Hu, Dongrui Liu, Zhilin Wang, Bo Li, Yu Cheng
              <br>
              <em>preprint</em>
              <br>
              <a href="https://github.com/zzzhr97/SpecBench">Github</a>
              /
              <a href="https://arxiv.org/abs/2509.14760">Paper</a>
              <p></p>
              <p>Reasoning over safety and behavourial boundaries before answering.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/unveil.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2502.15208" id="conf_deepfake-detect">
                <papertitle>Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing</papertitle>
              </a>
              <br>
              Zhilin Wang<sup>*</sup>,
              <strong>Yafu Li</strong><sup>*</sup><sup>&#8224</sup>,
              Jianhao Yan,
              Yu Cheng,
              Yue Zhang
              <br>
              <em><strong>ACL</strong></em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2502.15208">Paper</a>
              <p></p>
              <p>Unveiling attractor cycles in LLMs through dynamical systems analysis.</p>
            </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/deepfaketextdetect.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2305.13242" id="conf_deepfake-detect">
                <papertitle>MAGE: Machine-generated Text Detection in the Wild</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong>,
              Qintong Li,
              Leyang Cui,
              Wei Bi,
              Longyue Wang,
              Linyi Yang,
              Shuming Shi,
              Yue Zhang
              <br>
              <em><strong>ACL</strong></em>, 2024
              <br>
              <a href="https://github.com/yafuly/MAGE">Github</a>
              /
              <a href="https://arxiv.org/abs/2305.13242">Paper</a>
              <p></p>
              <p>Assessing the proficiency of machine-generated text detectors amidst real-world scenarios.</p>
            </td>
          </tr>
        
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ptd.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2405.12689" id="conf_ptd">
                <papertitle>Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong><sup>*</sup>,
              Zhilin Wang<sup>*</sup>,
              Leyang Cui,
              Wei Bi,
              Shumin Shi,
              Yue Zhang
              <br>
              <em><strong>ACL</strong> Findings</em>, 2024
              <br>
              <a href="https://github.com/Linzwcs/PASTED">Github</a>
              /
              <a href="https://arxiv.org/abs/2405.12689">Paper</a>
              <p></p>
              <p>We propose a novel task to identify "AI-touched" text spans in a fine-grained manner.</p>
            </td>
          </tr> -->
        
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/siren.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2309.01219" id="conf_siren">
                <papertitle>Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models</papertitle>
              </a>
              <br>
              Yue Zhang,
              <strong>Yafu Li</strong>,
              Leyang Cui,
              Deng Cai,
              Lemao Liu,
              Tingchen Fu,
              Xinting Huang,
              Enbo Zhao,
              Yu Zhang,
              Yulong Chen,
              Longyue Wang,
              Anh Tuan Luu,
              Wei Bi,
              Freda Shi,
              Shuming Shi
              <br>
              <em><strong>Computational Linguistics</strong></em>
              <br>
              <a href="https://github.com/hillzhang1999/llm-hallucination-survey">Github</a>
              /
              <a href="https://arxiv.org/abs/2309.01219">Paper</a>
              <p></p>
              <p>A survey of hallucination in LLMs.</p>
            </td>
          </tr>
        </tbody></table>
        
        <!-- Machine Translation Section -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Multilinguality</heading>
            </td>
          </tr>
        </tbody></table>
        
        <!-- Papers under Machine Translation -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/llm_trans.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2503.04369" id="conf_syn-gen">
                <papertitle>Lost in Literalism: How Supervised Training Shapes Translationese in LLMs</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong><sup>*</sup>,
              Ronghao Zhang<sup>*</sup>,
              Zhilin Wang,
              Huajiang Zhang,
              Leyang Cui,
              Yongjing Yin,
              Tong Xiao,
              Yue Zhang
              <br>
              <em><strong>ACL</strong></em>, 2025
              <br>
              <a href="https://github.com/yafuly/LLM_Translationese">Github</a>
              /
              <a href="https://arxiv.org/abs/2503.04369">Paper</a>
              <p></p>
              <p>A systematic study of the origin of translationese in LLMs and mitigation methods.</p>
            </td>    
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/syn_gen.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2306.11485" id="conf_syn-gen">
                <papertitle>Explicit Syntactic Guidance for Neural Text Generation</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong>,
              Leyang Cui,
              Jianhao Yan,
              Yongjing Yin,
              Wei Bi,
              Shuming Shi,
              Yue Zhang
              <br>
              <em><strong>ACL</strong></em>, 2023, <strong>Best Paper Nomination (1.6%)</strong>
              <br>
              <a href="https://github.com/yafuly/SyntaxGen">Github</a>
              /
              <a href="https://arxiv.org/abs/2306.11485">Paper</a>
              <p></p>
              <p>A neural symbolic method that guides generation with rules.</p>
            </td>    
          </tr>
        
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mgmo.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2210.11017" id="conf_mgmo">
                <papertitle>Multi-Granularity Optimization for Non-Autoregressive Translation</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong>,
              Leyang Cui,
              Yongjing Yin,
              Yue Zhang
              <br>
              <em><strong>EMNLP</strong></em>, 2022
              <br>
              <a href="https://github.com/yafuly/mgmo-nat">Github</a>
              /
              <a href="https://arxiv.org/abs/2210.11017">Paper</a>
              <p></p>
              <p>Optimizing non-autoregressive translation with multi-granularity policy gradient.</p>
            </td>    
          </tr>
        
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cg.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2105.14802v1" id="conf_lan">
                <papertitle>On Compositional Generalization of Neural Machine Translation</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong>,
              Yongjing Yin,
              Yulong Chen,
              Yue Zhang
              <br>
              <em><strong>ACL</strong></em>, 2021
              <br>
              <a href="https://github.com/yafuly/CoGnition">Github</a>
              /
              <a href="https://arxiv.org/abs/2105.14802v1">Paper</a>
              <p></p>
              <p>Neural machine translation suffers poor compositionality.</p>
            </td>    
          </tr>
          
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/nat_vs_at.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2405.12788" id="conf_nat-vs-at">
                <papertitle>What Have We Achieved on Non-autoregressive Translation?</papertitle>
              </a>
              <br>
              <strong>Yafu Li</strong><sup>*</sup>,
              Huajian Zhang<sup>*</sup>,
              Jianhao Yan,
              Yongjing Yin,
              Yue Zhang
              <br>
              <em><strong>ACL</strong> Findings</em>, 2024
              <br>
              <a href="https://github.com/HJZnlp/NAT_vs_AT">Github</a>
              /
              <a href="https://arxiv.org/abs/2405.12788">Paper</a>
              <p></p>
              <p>We present a systematic and comprehensive evaluation of NAT methods against AT.</p>
            </td>
          </tr> -->
        
          

        </tbody></table>


  <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Education</heading>
      <p>
        PhD in Computer Science, <strong>Zhejiang University</strong> and <strong>Westlake University</strong>
      </p>
      <p>
        Master of Science in Artificial Intelligence, <strong>University of Edinburgh</strong>
      </p>
      <p>
        Bachelor of Engineering in Electronic Information Engineering, <strong>Wuhan University</strong> 
      </p>
    </td>
  </tr>
</tbody></table> -->


  <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Experience</heading>
      <p>
        <strong>Research Intern</strong> at Tencent AI lab (2022.10-2024.5).
      </p>
      <p>
        <strong>Algorithem Engineer</strong> at Noah Ark's lab, Huawei (2018.12-2020.6).
      </p>
      <p>
        <strong>Software Engineering Intern</strong> at VMware, Beijing (2016.9-2017.5).
      </p>
    </td>
  </tr>
</tbody></table> -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Talks & Lectures</heading>
        <p>
          October 27, 2025 ‚Äî Invited lecture at <strong>Southern University of Science and Technology</strong>: <i> On the Evolution of Reasoning Abilities in Large Language Models</i>
        <p>
          September 4, 2025 ‚Äî Invited lecture at <strong>Tencent</strong>: <i>Evolving Reasoning Abilities of LLMs: RLVR, Off-Policy Learning, and Test-Time Reinforcement Learning</i>
        </p>
        <p>
          August 12, 2025 ‚Äî Invited speaker at <i><strong>CCL 2025</strong> Forum on Large Model Reasoning and Reinforcement Learning</i>
        </p>
      </td>
    </tr>
  </tbody>
</table>



  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Service</heading>
      <p>
        <strong>Area Chair:</strong> ACL 2025, EMNLP 2025
      </p>
      <p>
        <strong>Conference Reviewer:</strong> ACL, EMNLP, COLING, ACL ARR, IJCAI, NeurIPS.
      </p>
      <p>
        <strong>Journal Reviewer:</strong> TMLR, JAIR, TACL, TASLP, TBD, TALLIP.
      </p>
    </td>
  </tr>
</tbody></table>
  
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>Honor</heading>
    <p>
      <strong>Outstanding Student Scholarship</strong> (Silver medal, Tencent Rhino-Bird Elite Program, 2024).
    </p>
    <p>
      <strong>National Scholarship</strong> (Ministry of Education, 2023).
    </p>
    <p>
      <strong>Dean's Medal</strong> (Westlake University, 2023).
    </p>
  </td>
</tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:0px">
        <br>
        <p style="text-align:right;font-size:small;">
          Website's code is from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
          
        </p>
      </td>
    </tr>
  </tbody></table>
</td>
</tr>

</body>

</html>
